{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.corpus import Loader, Creator\n",
    "from src.models import W2V, MUSE\n",
    "from src.visualization import Visualizer\n",
    "from src.utils import series_to_arr\n",
    "import pandas as pd\n",
    "from src.evaluation import Evaluator\n",
    "import json\n",
    "import os\n",
    "from src.orchestration import Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_words = ['access', 'authoris', 'capit', 'committe', 'consum', 'content', 'deadlin', 'document', 'expenditur', 'full', 'geograph', 'group', 'growth', 'hear', 'instrument', 'investig', 'label', 'list', 'loan', 'network', 'opinion', 'partnership', 'pension', 'price', 'sale', 'secret', 'solut', 'trade', 'type', 'wast']\n",
    "cz_words = ['přístup', 'povolen', 'kapitál', 'výbor', 'spotřebitel', 'obsah', 'lhůt', 'dokument', 'výdaj', 'pln', 'zeměpisn', 'skup', 'růst', 'slyšen', 'nástroj', 'šetřen', 'označen', 'seznam', 'úvěr', 'síť', 'stanovisk', 'partnerst', 'důchod', 'cen', 'prodej', 'tajemstv', 'řešen', 'obchod', 'typ', 'odpad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'en_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m muse \u001b[38;5;241m=\u001b[39m MUSE(epoch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, en_model\u001b[38;5;241m=\u001b[39m\u001b[43men_model\u001b[49m, cz_model\u001b[38;5;241m=\u001b[39mcz_model, model_config\u001b[38;5;241m=\u001b[39mmodel_config)\n\u001b[1;32m      2\u001b[0m muse\u001b[38;5;241m.\u001b[39mrun_adversarial()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'en_model' is not defined"
     ]
    }
   ],
   "source": [
    "muse = MUSE(epoch_size=10000, epochs=1, en_model=en_model, cz_model=cz_model, model_config=model_config)\n",
    "muse.run_adversarial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "INTERLEAVED\n",
      "Context window: 6\n",
      "Vector size: 300\n",
      "Model type: CBOW\n",
      "------------------------------\n",
      "P@5:  0.7666666666666667\n",
      "P@10: 0.8\n",
      "------------------------------\n",
      "MUSE\n",
      "Context window: 3\n",
      "Vector size: 300\n",
      "Model type: CBOW\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Impossible to import Faiss-GPU. Switching to FAISS-CPU, this will be slower.\n",
      "\n",
      "INFO - 10/15/22 18:57:22 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 10/15/22 18:57:22 - 0:00:00 - adversarial: True\n",
      "                                     batch_size: 32\n",
      "                                     cuda: False\n",
      "                                     dico_build: S2T\n",
      "                                     dico_eval: default\n",
      "                                     dico_max_rank: 15000\n",
      "                                     dico_max_size: 0\n",
      "                                     dico_method: csls_knn_10\n",
      "                                     dico_min_size: 0\n",
      "                                     dico_threshold: 0\n",
      "                                     dis_clip_weights: 0\n",
      "                                     dis_dropout: 0.0\n",
      "                                     dis_hid_dim: 2048\n",
      "                                     dis_input_dropout: 0.1\n",
      "                                     dis_lambda: 1\n",
      "                                     dis_layers: 2\n",
      "                                     dis_most_frequent: 0\n",
      "                                     dis_optimizer: sgd,lr=0.1\n",
      "                                     dis_smooth: 0.1\n",
      "                                     dis_steps: 5\n",
      "                                     emb_dim: 300\n",
      "                                     epoch_size: 1\n",
      "                                     exp_id: cbow3x300\n",
      "                                     exp_name: muse\n",
      "                                     exp_path: ./embeddings/muse/cbow3x300\n",
      "                                     export: txt\n",
      "                                     lr_decay: 0.98\n",
      "                                     lr_shrink: 0.5\n",
      "                                     map_beta: 0.001\n",
      "                                     map_id_init: True\n",
      "                                     map_optimizer: sgd,lr=0.1\n",
      "                                     max_vocab: 200000\n",
      "                                     min_lr: 1e-06\n",
      "                                     n_epochs: 5000\n",
      "                                     n_refinement: 0\n",
      "                                     normalize_embeddings: \n",
      "                                     seed: -1\n",
      "                                     src_emb: ./embeddings/unaligned/cbow3x300/cz.txt\n",
      "                                     src_lang: cz\n",
      "                                     tgt_emb: ./embeddings/unaligned/cbow3x300/en.txt\n",
      "                                     tgt_lang: en\n",
      "                                     verbose: 2\n",
      "INFO - 10/15/22 18:57:22 - 0:00:00 - The experiment will be stored in ./embeddings/muse/cbow3x300\n",
      "INFO - 10/15/22 18:57:24 - 0:00:03 - Loaded 99175 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:57:27 - 0:00:05 - Loaded 86097 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:57:27 - 0:00:06 - ----> ADVERSARIAL TRAINING <----\n",
      "                                     \n",
      "                                     \n",
      "INFO - 10/15/22 18:57:27 - 0:00:06 - Starting adversarial training epoch 0...\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  src_emb = self.src_emb(Variable(src_ids, volatile=True))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  tgt_emb = self.tgt_emb(Variable(tgt_ids, volatile=True))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:71: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  src_emb = self.mapping(Variable(src_emb.data, volatile=volatile))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  tgt_emb = Variable(tgt_emb.data, volatile=volatile)\n",
      "INFO - 10/15/22 18:57:27 - 0:00:06 - 000000 - Discriminator loss: 0.6929 - 776 samples/s\n",
      "INFO - 10/15/22 18:57:37 - 0:00:15 - Building the train dictionary ...\n",
      "INFO - 10/15/22 18:57:37 - 0:00:15 - New train dictionary of 908 pairs.\n",
      "INFO - 10/15/22 18:57:37 - 0:00:15 - Mean cosine (nn method, S2T build, 10000 max size): 0.30661\n",
      "INFO - 10/15/22 19:08:50 - 0:11:28 - Building the train dictionary ...\n",
      "INFO - 10/15/22 19:08:50 - 0:11:28 - New train dictionary of 567 pairs.\n",
      "INFO - 10/15/22 19:08:50 - 0:11:28 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.29575\n",
      "/home/lukas/School/vylet/MUSE/src/evaluation/evaluator.py:232: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  emb = Variable(self.src_emb.weight[i:i + bs].data, volatile=True)\n",
      "/home/lukas/School/vylet/MUSE/src/evaluation/evaluator.py:237: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  emb = Variable(self.tgt_emb.weight[i:i + bs].data, volatile=True)\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - Discriminator source / target predictions: 0.49871 / 0.49783\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - Discriminator source / target / global accuracy: 0.10339 / 0.97532 / 0.50858\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - __log__:{\"n_epoch\": 0, \"mean_cosine-nn-S2T-10000\": 0.3066137433052063, \"mean_cosine-csls_knn_10-S2T-10000\": 0.2957482635974884, \"dis_accu\": 0.5085819767692905, \"dis_src_pred\": 0.4987115908221992, \"dis_tgt_pred\": 0.4978311105567265}\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.29575\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - * Saving the mapping to ./embeddings/muse/cbow3x300/best_mapping.pth ...\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - End of epoch 0.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - Decreasing learning rate: 0.10000000 -> 0.09800000\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - Starting adversarial training epoch 1...\n",
      "INFO - 10/15/22 19:08:55 - 0:11:34 - 000000 - Discriminator loss: 0.6922 - 820 samples/s\n",
      "INFO - 10/15/22 19:09:04 - 0:11:43 - Building the train dictionary ...\n",
      "INFO - 10/15/22 19:09:04 - 0:11:43 - New train dictionary of 910 pairs.\n",
      "INFO - 10/15/22 19:09:04 - 0:11:43 - Mean cosine (nn method, S2T build, 10000 max size): 0.30658\n",
      "INFO - 10/15/22 19:20:25 - 0:23:04 - Building the train dictionary ...\n",
      "INFO - 10/15/22 19:20:25 - 0:23:04 - New train dictionary of 567 pairs.\n",
      "INFO - 10/15/22 19:20:25 - 0:23:04 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.29579\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - Discriminator source / target predictions: 0.49956 / 0.49756\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - Discriminator source / target / global accuracy: 0.20982 / 0.97329 / 0.56461\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - __log__:{\"n_epoch\": 1, \"mean_cosine-nn-S2T-10000\": 0.30657604336738586, \"mean_cosine-csls_knn_10-S2T-10000\": 0.2957867681980133, \"dis_accu\": 0.5646077119046591, \"dis_src_pred\": 0.49955694912301524, \"dis_tgt_pred\": 0.4975639767229584}\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.29579\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - * Saving the mapping to ./embeddings/muse/cbow3x300/best_mapping.pth ...\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - End of epoch 1.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - Decreasing learning rate: 0.09800000 -> 0.09604000\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - Starting adversarial training epoch 2...\n",
      "INFO - 10/15/22 19:20:31 - 0:23:10 - 000000 - Discriminator loss: 0.6914 - 819 samples/s\n",
      "INFO - 10/15/22 19:20:40 - 0:23:19 - Building the train dictionary ...\n",
      "INFO - 10/15/22 19:20:40 - 0:23:19 - New train dictionary of 911 pairs.\n",
      "INFO - 10/15/22 19:20:40 - 0:23:19 - Mean cosine (nn method, S2T build, 10000 max size): 0.30653\n"
     ]
    }
   ],
   "source": [
    "orch = Orchestrator(en_words=en_words, cz_words=cz_words,\n",
    "                    muse_epoch_size=1, muse_epochs=5000,\n",
    "                    vector_sizes=[300], window_sizes=[6])\n",
    "orch.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Impossible to import Faiss-GPU. Switching to FAISS-CPU, this will be slower.\n",
      "\n",
      "INFO - 10/15/22 18:21:19 - 0:00:00 - ============ Initialized logger ============\n",
      "INFO - 10/15/22 18:21:19 - 0:00:00 - adversarial: True\n",
      "                                     batch_size: 32\n",
      "                                     cuda: False\n",
      "                                     dico_build: S2T\n",
      "                                     dico_eval: default\n",
      "                                     dico_max_rank: 15000\n",
      "                                     dico_max_size: 0\n",
      "                                     dico_method: csls_knn_10\n",
      "                                     dico_min_size: 0\n",
      "                                     dico_threshold: 0\n",
      "                                     dis_clip_weights: 0\n",
      "                                     dis_dropout: 0.0\n",
      "                                     dis_hid_dim: 2048\n",
      "                                     dis_input_dropout: 0.1\n",
      "                                     dis_lambda: 1\n",
      "                                     dis_layers: 2\n",
      "                                     dis_most_frequent: 0\n",
      "                                     dis_optimizer: sgd,lr=0.1\n",
      "                                     dis_smooth: 0.1\n",
      "                                     dis_steps: 5\n",
      "                                     emb_dim: 300\n",
      "                                     epoch_size: 10000\n",
      "                                     exp_id: cbow3x300\n",
      "                                     exp_name: muse\n",
      "                                     exp_path: ./embeddings/muse/cbow3x300\n",
      "                                     export: txt\n",
      "                                     lr_decay: 0.98\n",
      "                                     lr_shrink: 0.5\n",
      "                                     map_beta: 0.001\n",
      "                                     map_id_init: True\n",
      "                                     map_optimizer: sgd,lr=0.1\n",
      "                                     max_vocab: 200000\n",
      "                                     min_lr: 1e-06\n",
      "                                     n_epochs: 1\n",
      "                                     n_refinement: 0\n",
      "                                     normalize_embeddings: \n",
      "                                     seed: -1\n",
      "                                     src_emb: embeddings/unaligned/cbow_3x300/cz.txt\n",
      "                                     src_lang: cz\n",
      "                                     tgt_emb: embeddings/unaligned/cbow_3x300/en.txt\n",
      "                                     tgt_lang: en\n",
      "                                     verbose: 2\n",
      "INFO - 10/15/22 18:21:19 - 0:00:00 - The experiment will be stored in ./embeddings/muse/cbow3x300\n",
      "INFO - 10/15/22 18:21:21 - 0:00:03 - Loaded 99175 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:21:24 - 0:00:05 - Loaded 86097 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:21:24 - 0:00:05 - ----> ADVERSARIAL TRAINING <----\n",
      "                                     \n",
      "                                     \n",
      "INFO - 10/15/22 18:21:24 - 0:00:05 - Starting adversarial training epoch 0...\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:69: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  src_emb = self.src_emb(Variable(src_ids, volatile=True))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:70: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  tgt_emb = self.tgt_emb(Variable(tgt_ids, volatile=True))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:71: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  src_emb = self.mapping(Variable(src_emb.data, volatile=volatile))\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:72: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  tgt_emb = Variable(tgt_emb.data, volatile=volatile)\n",
      "INFO - 10/15/22 18:21:24 - 0:00:06 - 000000 - Discriminator loss: 0.6931 - 255 samples/s\n",
      "INFO - 10/15/22 18:21:34 - 0:00:15 - 004000 - Discriminator loss: 0.6407 - 857 samples/s\n",
      "INFO - 10/15/22 18:21:43 - 0:00:24 - 008000 - Discriminator loss: 0.5921 - 887 samples/s\n",
      "INFO - 10/15/22 18:21:56 - 0:00:37 - Building the train dictionary ...\n",
      "INFO - 10/15/22 18:21:56 - 0:00:37 - New train dictionary of 1329 pairs.\n",
      "INFO - 10/15/22 18:21:56 - 0:00:37 - Mean cosine (nn method, S2T build, 10000 max size): 0.68364\n",
      "INFO - 10/15/22 18:33:28 - 0:12:10 - Building the train dictionary ...\n",
      "INFO - 10/15/22 18:33:28 - 0:12:10 - New train dictionary of 1594 pairs.\n",
      "INFO - 10/15/22 18:33:28 - 0:12:10 - Mean cosine (csls_knn_10 method, S2T build, 10000 max size): 0.60788\n",
      "/home/lukas/School/vylet/MUSE/src/evaluation/evaluator.py:232: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  emb = Variable(self.src_emb.weight[i:i + bs].data, volatile=True)\n",
      "/home/lukas/School/vylet/MUSE/src/evaluation/evaluator.py:237: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  emb = Variable(self.tgt_emb.weight[i:i + bs].data, volatile=True)\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - Discriminator source / target predictions: 0.69682 / 0.49744\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - Discriminator source / target / global accuracy: 0.99310 / 0.38550 / 0.71074\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - __log__:{\"n_epoch\": 0, \"mean_cosine-nn-S2T-10000\": 0.6836414933204651, \"mean_cosine-csls_knn_10-S2T-10000\": 0.607875406742096, \"dis_accu\": 0.7107442031175785, \"dis_src_pred\": 0.6968192705810295, \"dis_tgt_pred\": 0.49744482354055136}\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - * Best value for \"mean_cosine-csls_knn_10-S2T-10000\": 0.60788\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - * Saving the mapping to ./embeddings/muse/cbow3x300/best_mapping.pth ...\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - End of epoch 0.\n",
      "                                     \n",
      "                                     \n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - Decreasing learning rate: 0.10000000 -> 0.09800000\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - * Reloading the best model from ./embeddings/muse/cbow3x300/best_mapping.pth ...\n",
      "INFO - 10/15/22 18:33:34 - 0:12:15 - Reloading all embeddings for mapping ...\n",
      "INFO - 10/15/22 18:33:37 - 0:12:18 - Loaded 99175 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:33:39 - 0:12:20 - Loaded 86097 pre-trained word embeddings.\n",
      "INFO - 10/15/22 18:33:39 - 0:12:20 - Map source embeddings to the target space ...\n",
      "/home/lukas/School/vylet/MUSE/src/trainer.py:262: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  x = Variable(src_emb[k:k + bs], volatile=True)\n",
      "INFO - 10/15/22 18:33:39 - 0:12:20 - Writing source embeddings to ./embeddings/muse/cbow3x300/vectors-cz.txt ...\n",
      "INFO - 10/15/22 18:34:06 - 0:12:47 - Writing target embeddings to ./embeddings/muse/cbow3x300/vectors-en.txt ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"\"\"python MUSE/unsupervised.py\\\n",
    "                --cuda False --n_refinement 0\\\n",
    "                --dis_most_frequent 0\\\n",
    "                --src_emb embeddings/unaligned/cbow_3x300/cz.txt --src_lang cz\\\n",
    "                --tgt_emb embeddings/unaligned/cbow_3x300/en.txt --tgt_lang en\\\n",
    "                --emb_dim 300\\\n",
    "                --exp_path ./embeddings\\\n",
    "                --exp_name muse\\\n",
    "                --exp_id cbow3x300\\\n",
    "                --epoch_size 10000\\\n",
    "                --n_epochs 1\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUSE: ./MUSE/unsupervised.py\n",
      "cz: ./embeddings/unaligned/cbow3x300/cz.txt\n",
      "en: ./embeddings/unaligned/cbow3x300/en.txt\n",
      "exp_path: ./embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Impossible to import Faiss-GPU. Switching to FAISS-CPU, this will be slower.\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"./MUSE/unsupervised.py\", line 82, in <module>\n",
      "    assert not params.cuda or torch.cuda.is_available()\n",
      "AssertionError\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_emb = os.path.join(root_path, 'embeddings/unaligned/cbow3x300/cz.txt')\n",
    "tgt_emb = os.path.join(root_path, 'embeddings/unaligned/cbow3x300/en.txt')\n",
    "muse_exec = os.path.join(root_path, 'MUSE/unsupervised.py')\n",
    "exp_path = os.path.join(root_path, 'embeddings')\n",
    "print('MUSE:', muse_exec)\n",
    "print('cz:', src_emb)\n",
    "print('en:', tgt_emb)\n",
    "print('exp_path:', exp_path)\n",
    "os.system(f\"\"\"python {muse_exec}\\\n",
    "                --cuda True --n_refinement 0\\\n",
    "                --dis_most_frequent 0\\\n",
    "                --src_emb {src_emb} --src_lang cz\\\n",
    "                --tgt_emb {tgt_emb} --tgt_lang en\\\n",
    "                --emb_dim 300\\\n",
    "                --exp_path {exp_path}\\\n",
    "                --exp_name muse\\\n",
    "                --exp_id cbow3x300\\\n",
    "                --epoch_size 10000\\\n",
    "                --n_epochs 1\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
